{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.0.1.post2\n",
      "Torchvision Version:  0.2.2\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms\n",
    "#   to the ImageFolder structure\n",
    "data_dir = \"./data/hymenoptera_data\"\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"squeezenet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 15\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/squeezenet1_0-a815701f.pth\" to /home/nasaa/.torch/models/squeezenet1_0-a815701f.pth\n",
      "5017600.0 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SqueezeNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (3): Fire(\n",
      "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (4): Fire(\n",
      "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (5): Fire(\n",
      "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (7): Fire(\n",
      "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (8): Fire(\n",
      "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (9): Fire(\n",
      "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (10): Fire(\n",
      "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (12): Fire(\n",
      "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): ReLU(inplace)\n",
      "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.1.weight\n",
      "\t classifier.1.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.5363 Acc: 0.7623\n",
      "val Loss: 0.3872 Acc: 0.8693\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.2700 Acc: 0.8811\n",
      "val Loss: 0.3610 Acc: 0.8954\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.2423 Acc: 0.9057\n",
      "val Loss: 0.3464 Acc: 0.8954\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.1678 Acc: 0.9549\n",
      "val Loss: 0.3161 Acc: 0.9346\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.2024 Acc: 0.9139\n",
      "val Loss: 0.2982 Acc: 0.9346\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.1690 Acc: 0.9344\n",
      "val Loss: 0.3078 Acc: 0.9412\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.1505 Acc: 0.9426\n",
      "val Loss: 0.3369 Acc: 0.9085\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.1662 Acc: 0.9344\n",
      "val Loss: 0.2997 Acc: 0.9346\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.1601 Acc: 0.9344\n",
      "val Loss: 0.3207 Acc: 0.9412\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.1444 Acc: 0.9385\n",
      "val Loss: 0.3200 Acc: 0.9346\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.1176 Acc: 0.9508\n",
      "val Loss: 0.3372 Acc: 0.9281\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.1839 Acc: 0.9262\n",
      "val Loss: 0.3098 Acc: 0.9085\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.1445 Acc: 0.9303\n",
      "val Loss: 0.2953 Acc: 0.9281\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.1474 Acc: 0.9385\n",
      "val Loss: 0.3016 Acc: 0.9346\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.1262 Acc: 0.9508\n",
      "val Loss: 0.3746 Acc: 0.8954\n",
      "\n",
      "Training complete in 0m 59s\n",
      "Best val Acc: 0.941176\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.6960 Acc: 0.5041\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.6877 Acc: 0.5082\n",
      "val Loss: 0.6931 Acc: 0.4510\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.6926 Acc: 0.5041\n",
      "val Loss: 0.6931 Acc: 0.5033\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.6862 Acc: 0.5041\n",
      "val Loss: 0.7050 Acc: 0.4575\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.6981 Acc: 0.5246\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.6929 Acc: 0.5123\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.6924 Acc: 0.4959\n",
      "val Loss: 0.6931 Acc: 0.5163\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.6880 Acc: 0.4959\n",
      "val Loss: 0.6931 Acc: 0.4902\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.6930 Acc: 0.5328\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.6932 Acc: 0.5082\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.6932 Acc: 0.4877\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5082\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5164\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.6932 Acc: 0.4959\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5000\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Training complete in 0m 50s\n",
      "Best val Acc: 0.516340\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scratch_model,_ = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=False)\n",
    "scratch_model = scratch_model.to(device)\n",
    "scratch_optimizer = optim.SGD(scratch_model.parameters(), lr=0.001, momentum=0.9)\n",
    "scratch_criterion = nn.CrossEntropyLoss()\n",
    "_,scratch_hist = train_model(scratch_model, dataloaders_dict, scratch_criterion, scratch_optimizer, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
    "\n",
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "ohist = []\n",
    "shist = []\n",
    "\n",
    "ohist = [h.cpu().numpy() for h in hist]\n",
    "shist = [h.cpu().numpy() for h in scratch_hist]\n",
    "\n",
    "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "plt.plot(range(1,num_epochs+1),shist,label=\"Scratch\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
